{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second level scraper code to scrape the details of the restaurants and also the comments of the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from requests import get\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from time import time \n",
    "from IPython.core.display import clear_output\n",
    "from warnings import warn\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Restaurant Type</th>\n",
       "      <th>Webpage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Positano @ RP</td>\n",
       "      <td>Italian, European</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Grand Shanghai Restaurant</td>\n",
       "      <td>Chinese, Asian</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. Fu Lin Men (NSRCC)</td>\n",
       "      <td>Chinese, Seafood</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. Entre-Nous creperie</td>\n",
       "      <td>French, European</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. NOX - Dine in the Dark</td>\n",
       "      <td>European, Fusion</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6. The Mind Cafe</td>\n",
       "      <td>Cafe, Pub</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7. Song Garden</td>\n",
       "      <td>Chinese, Asian</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8. Fu Lin Men (CSC)</td>\n",
       "      <td>Chinese, Asian</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9. Melt Cafe</td>\n",
       "      <td>International</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10. Positano Risto</td>\n",
       "      <td>Italian, Pizza</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Restaurant Name    Restaurant Type  \\\n",
       "0              1. Positano @ RP  Italian, European   \n",
       "1  2. Grand Shanghai Restaurant     Chinese, Asian   \n",
       "2         3. Fu Lin Men (NSRCC)   Chinese, Seafood   \n",
       "3        4. Entre-Nous creperie   French, European   \n",
       "4     5. NOX - Dine in the Dark   European, Fusion   \n",
       "5              6. The Mind Cafe          Cafe, Pub   \n",
       "6                7. Song Garden     Chinese, Asian   \n",
       "7           8. Fu Lin Men (CSC)     Chinese, Asian   \n",
       "8                  9. Melt Cafe      International   \n",
       "9            10. Positano Risto     Italian, Pizza   \n",
       "\n",
       "                                             Webpage  \n",
       "0  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "1  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "2  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "3  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "4  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "5  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "6  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "7  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "8  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "9  https://www.tripadvisor.com.sg/Restaurant_Revi...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve dataframe of links scraped previously\n",
    "links_df = pd.read_csv('./data/trip-advisor-scraper-main-url.csv')\n",
    "links_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positano @ RP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grand Shanghai Restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fu Lin Men (NSRCC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Entre-Nous creperie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX - Dine in the Dark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Restaurant Name\n",
       "0              Positano @ RP\n",
       "1  Grand Shanghai Restaurant\n",
       "2         Fu Lin Men (NSRCC)\n",
       "3        Entre-Nous creperie\n",
       "4     NOX - Dine in the Dark"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning of name in the restaurant name column using regex\n",
    "regex = '^([0-9])+\\. '\n",
    "links_df['Restaurant Name'].replace(regex,'',regex=True, inplace = True)\n",
    "links_df[['Restaurant Name']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Restaurant Type</th>\n",
       "      <th>Webpage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positano @ RP</td>\n",
       "      <td>Italian, European</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grand Shanghai Restaurant</td>\n",
       "      <td>Chinese, Asian</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fu Lin Men (NSRCC)</td>\n",
       "      <td>Chinese, Seafood</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Entre-Nous creperie</td>\n",
       "      <td>French, European</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX - Dine in the Dark</td>\n",
       "      <td>European, Fusion</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Restaurant Name    Restaurant Type  \\\n",
       "0              Positano @ RP  Italian, European   \n",
       "1  Grand Shanghai Restaurant     Chinese, Asian   \n",
       "2         Fu Lin Men (NSRCC)   Chinese, Seafood   \n",
       "3        Entre-Nous creperie   French, European   \n",
       "4     NOX - Dine in the Dark   European, Fusion   \n",
       "\n",
       "                                             Webpage  \n",
       "0  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "1  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "2  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "3  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "4  https://www.tripadvisor.com.sg/Restaurant_Revi...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1013"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the links out\n",
    "#list(links_df[\"Webpage\"])\n",
    "# check if length is correct\n",
    "len(list(links_df[\"Webpage\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d21180746-Reviews-Positano_RP-Singapore.html',\n",
       " 'https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d1145149-Reviews-Grand_Shanghai_Restaurant-Singapore.html',\n",
       " 'https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d17171783-Reviews-Fu_Lin_Men_NSRCC-Singapore.html',\n",
       " 'https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d1193730-Reviews-Entre_Nous_creperie-Singapore.html',\n",
       " 'https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d4611806-Reviews-NOX_Dine_in_the_Dark-Singapore.html']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store links as a list\n",
    "LIST_OF_LINKS = list(links_df[\"Webpage\"])\n",
    "# show first 5 links\n",
    "LIST_OF_LINKS[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100', '110', '120', '130', '140', '150', '160', '170', '180', '190', '200', '210', '220', '230', '240', '250', '260', '270', '280', '290', '300', '310', '320', '330', '340', '350', '360', '370', '380', '390', '400', '410', '420', '430', '440', '450', '460', '470', '480', '490', '500'] \n",
      "Number of pages scraped: 51\n"
     ]
    }
   ],
   "source": [
    "# get the start value for every new page in yelp\n",
    "start_of_new_page = [str(i) for i in range(0,501,10)]\n",
    "# debug\n",
    "print(start_of_new_page, end=' ')\n",
    "print(f'\\nNumber of pages scraped: {len(start_of_new_page)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For initial scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scraper(list_of_links, num_req, start, end):\n",
    "    # redeclaring lists to store data in multiple values\n",
    "    cust_names = []\n",
    "    cust_ratings = []\n",
    "    cust_comments = []\n",
    "    res_names = []\n",
    "    res_types = []\n",
    "\n",
    "    # counter\n",
    "    count = 0\n",
    "\n",
    "    # flag variable to check the scrape\n",
    "    # if unsuccessful scrape, try again\n",
    "    unsuccessful = True\n",
    "\n",
    "    # preparing the monitoring of the loop\n",
    "    start_time = time()\n",
    "\n",
    "    ### ----- \n",
    "\n",
    "    # for every comment in the interval of 10\n",
    "    for link_raw in list_of_links[start:end+1]:\n",
    "        loop_time = time()\n",
    "        count+=1 # increment count to determine which link it is being scraped\n",
    "        requests=1 # reset requests count for different webpage\n",
    "        # print(f'----- LINK {count} -----')\n",
    "        for pageStart in start_of_new_page:\n",
    "\n",
    "            # Break the loop if the number of requests is greater than expected\n",
    "            if requests > num_req:\n",
    "                #warn('Number of requests was greater than expected.')\n",
    "                break\n",
    "\n",
    "            unsuccessful = True\n",
    "            fail_count = 0\n",
    "            repeat = 0\n",
    "\n",
    "            while unsuccessful:\n",
    "                # make a get request\n",
    "                #response = get(f'https://www.yelp.com/biz/jumbo-seafood-singapore-4?start={pageStart}')\n",
    "                #response = get(f'https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d7348336-Reviews-or{pageStart}-Sunday_Folks-Singapore.html')\n",
    "                link_array = link_raw.split('Reviews-')\n",
    "                link = link_array[0] + 'Reviews-' + 'or' + str(pageStart) + \"-\" +link_array[1]\n",
    "                # print(link)\n",
    "                response = get(link)\n",
    "\n",
    "                # pause the loop\n",
    "                sleep(randint(2,5))\n",
    "\n",
    "                # monitor the requests\n",
    "                elapsed_time = time() - start_time\n",
    "                print(f'LINK {count+start} REQUEST {requests}; Frequency: {requests/elapsed_time} requests/s')\n",
    "\n",
    "                # Parse the content of the request with BeautifulSoup\n",
    "                page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                # get the comment container for all 20 comments in a page\n",
    "                comment_containers = page_html.find_all('div', class_='review-container')\n",
    "\n",
    "                if len(comment_containers) != 0:\n",
    "                    print(f\"REQUEST {requests}: SUCCESS --> Failed Count: {fail_count}\")\n",
    "                    clear_output(wait = True)\n",
    "                    unsuccessful = False\n",
    "                else:\n",
    "                    fail_count+=1\n",
    "                    repeat+=1\n",
    "                    #print(f\"Request {requests}: unsuccessful scrape\") # debug\n",
    "                if repeat >= 5:\n",
    "                    print(\"Repeated 5 times --> cannot scrape\")\n",
    "                    break\n",
    "\n",
    "            requests += 1\n",
    "\n",
    "            # for every comments in 10\n",
    "            for com in comment_containers:\n",
    "                # in case the scrape fail for that particular entry due to html tag issue\n",
    "                try:\n",
    "                    # append the restaurant name and type\n",
    "                    res_names.append(links_df[\"Restaurant Name\"][count+start-1])\n",
    "                    res_types.append(links_df[\"Restaurant Type\"][count+start-1])\n",
    "\n",
    "                    # scrape the customer name\n",
    "                    cust_name = com.find('div', class_='info_text pointer_cursor').text\n",
    "                    cust_names.append(cust_name)\n",
    "\n",
    "                    # scrape the customer ratings\n",
    "                    cust_rating_raw = com.find('div', class_ ='ui_column is-9').span['class']\n",
    "\n",
    "                    # convert the rating to an integer\n",
    "                    cust_rating = 0\n",
    "                    if cust_rating_raw[1] == 'bubble_50':\n",
    "                        cust_rating = 5\n",
    "                    elif cust_rating_raw[1] == 'bubble_40':\n",
    "                        cust_rating = 4\n",
    "                    elif cust_rating_raw[1] == 'bubble_30':\n",
    "                        cust_rating = 3\n",
    "                    elif cust_rating_raw[1] == 'bubble_20':\n",
    "                        cust_rating = 2\n",
    "                    elif cust_rating_raw[1] == 'bubble_10':\n",
    "                        cust_rating = 1\n",
    "                    else:\n",
    "                        cust_rating = 0\n",
    "                    cust_ratings.append(cust_rating)\n",
    "\n",
    "                    # scrape the customer comment\n",
    "                    cust_comment_raw = com.find('div', class_='entry').text\n",
    "\n",
    "                    # get rid of the unwanted characters like \"...\" and \"More\"\n",
    "                    comment_ = cust_comment_raw.replace(\"...\",\" \")\n",
    "\n",
    "                    # remove instances with \"More\" tab if there are more words\n",
    "                    cust_comment = \"\"\n",
    "                    if comment_[-4:] == \"More\":\n",
    "                        cust_comment = comment_[:-4]\n",
    "                    else:\n",
    "                        cust_comment = comment_\n",
    "\n",
    "                    cust_comments.append(cust_comment)\n",
    "                except:\n",
    "                    print(f'error in request {requests}')\n",
    "                    continue\n",
    "\n",
    "            # Throw a warning for non-200 status codes\n",
    "            if response.status_code != 200:\n",
    "                warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
    "        # check time needed to exceute one link\n",
    "        print(f'Time taken for scraping link {count+start}: {time() - loop_time} seconds')\n",
    "\n",
    "    print('DONE')\n",
    "    return cust_names, cust_ratings, cust_comments, res_names, res_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraper call function\n",
    "def scraper_call(list_of_links, num_req, start, end):\n",
    "    cust_names, cust_ratings, cust_comments, res_names, res_types = scraper(list_of_links = list_of_links, \n",
    "                                                                            num_req=num_req, \n",
    "                                                                            start=start, \n",
    "                                                                            end=end)\n",
    "    print(f'Number of entries: {len(cust_names)}')\n",
    "    review = pd.DataFrame({\n",
    "        'Restaurant Name': res_names,\n",
    "        'Restaurant Type': res_types,\n",
    "        'Reviewer\\'s Name': cust_names,\n",
    "        'Rating': cust_ratings,\n",
    "        'Comment': cust_comments, \n",
    "    })\n",
    "\n",
    "    print(review.info())\n",
    "    if start == 0:\n",
    "        review.to_csv('./data/trip-advisor-comments.csv', mode='a', index=False)\n",
    "    else:\n",
    "        review.to_csv('./data/trip-advisor-comments.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper_v2(list_of_links, num_req, start, end):\n",
    "    # redeclaring lists to store data in multiple values\n",
    "    cust_names = []\n",
    "    cust_ratings = []\n",
    "    cust_comments = []\n",
    "    res_names = []\n",
    "    res_types = []\n",
    "\n",
    "    # counter\n",
    "    count = 0\n",
    "\n",
    "    # flag variable to check the scrape\n",
    "    # if unsuccessful scrape, try again\n",
    "    unsuccessful = True\n",
    "\n",
    "    # preparing the monitoring of the loop\n",
    "    start_time = time()\n",
    "\n",
    "    ### ----- \n",
    "\n",
    "    # for every comment in the interval of 10\n",
    "    for link_raw in list_of_links[start:end+1]:\n",
    "        loop_time = time()\n",
    "        count+=1 # increment count to determine which link it is being scraped\n",
    "        requests=1 # reset requests count for different webpage\n",
    "        # print(f'----- LINK {count} -----')\n",
    "        for pageStart in start_of_new_page:\n",
    "\n",
    "            # Break the loop if the number of requests is greater than expected\n",
    "            if requests > num_req:\n",
    "                #warn('Number of requests was greater than expected.')\n",
    "                break\n",
    "\n",
    "            unsuccessful = True\n",
    "            fail_count = 0\n",
    "            repeat = 0\n",
    "\n",
    "            while unsuccessful:\n",
    "                # make a get request\n",
    "                #response = get(f'https://www.yelp.com/biz/jumbo-seafood-singapore-4?start={pageStart}')\n",
    "                #response = get(f'https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d7348336-Reviews-or{pageStart}-Sunday_Folks-Singapore.html')\n",
    "                link_array = link_raw.split('Reviews-')\n",
    "                link = link_array[0] + 'Reviews-' + 'or' + str(pageStart) + \"-\" +link_array[1]\n",
    "                # print(link)\n",
    "                response = get(link)\n",
    "\n",
    "                # pause the loop\n",
    "                sleep(randint(2,5))\n",
    "\n",
    "                # monitor the requests\n",
    "                elapsed_time = time() - start_time\n",
    "                print(f'LINK {count+start} REQUEST {requests}; Frequency: {requests/elapsed_time} requests/s')\n",
    "\n",
    "                # Parse the content of the request with BeautifulSoup\n",
    "                page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                # get the comment container for all 20 comments in a page\n",
    "                comment_containers = page_html.find_all('div', class_='review-container')\n",
    "\n",
    "                if len(comment_containers) != 0:\n",
    "                    print(f\"REQUEST {requests}: SUCCESS --> Failed Count: {fail_count}\")\n",
    "                    clear_output(wait = True)\n",
    "                    unsuccessful = False\n",
    "                else:\n",
    "                    fail_count+=1\n",
    "                    repeat+=1\n",
    "                    #print(f\"Request {requests}: unsuccessful scrape\") # debug\n",
    "                if repeat >= 5:\n",
    "                    print(\"Repeated 5 times --> cannot scrape\")\n",
    "                    break\n",
    "\n",
    "            requests += 1\n",
    "\n",
    "            # for every comments in 10\n",
    "            for com in comment_containers:\n",
    "                # in case the scrape fail for that particular entry due to html tag issue\n",
    "                try:\n",
    "                    # append the restaurant name and type\n",
    "                    res_names.append(links_df[\"Restaurant Name\"][count+start-1])\n",
    "                    res_types.append(links_df[\"Restaurant Type\"][count+start-1])\n",
    "\n",
    "                    # scrape the customer name\n",
    "                    cust_name = com.find('div', class_='info_text pointer_cursor').text\n",
    "                    cust_names.append(cust_name)\n",
    "\n",
    "                    # scrape the customer ratings\n",
    "                    cust_rating_raw = com.find('div', class_ ='ui_column is-9').span['class']\n",
    "\n",
    "                    # convert the rating to an integer\n",
    "                    cust_rating = 0\n",
    "                    if cust_rating_raw[1] == 'bubble_50':\n",
    "                        cust_rating = 5\n",
    "                    elif cust_rating_raw[1] == 'bubble_40':\n",
    "                        cust_rating = 4\n",
    "                    elif cust_rating_raw[1] == 'bubble_30':\n",
    "                        cust_rating = 3\n",
    "                    elif cust_rating_raw[1] == 'bubble_20':\n",
    "                        cust_rating = 2\n",
    "                    elif cust_rating_raw[1] == 'bubble_10':\n",
    "                        cust_rating = 1\n",
    "                    else:\n",
    "                        cust_rating = 0\n",
    "                    cust_ratings.append(cust_rating)\n",
    "\n",
    "                    # scrape the customer comment\n",
    "                    cust_comment_raw = com.find('div', class_='entry').text\n",
    "\n",
    "                    # get rid of the unwanted characters like \"...\" and \"More\"\n",
    "                    comment_ = cust_comment_raw.replace(\"...\",\" \")\n",
    "\n",
    "                    # remove instances with \"More\" tab if there are more words\n",
    "                    cust_comment = \"\"\n",
    "                    if comment_[-4:] == \"More\":\n",
    "                        cust_comment = comment_[:-4]\n",
    "                    else:\n",
    "                        cust_comment = comment_\n",
    "\n",
    "                    cust_comments.append(cust_comment)\n",
    "                except:\n",
    "                    print(f'error in request {requests}')\n",
    "                    continue\n",
    "\n",
    "            # Throw a warning for non-200 status codes\n",
    "            if response.status_code != 200:\n",
    "                warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
    "        # check time needed to exceute one link\n",
    "        print(f'Time taken for scraping link {count+start}: {time() - loop_time} seconds')\n",
    "        \n",
    "        print(f'Number of entries: {len(cust_names)}')\n",
    "        \n",
    "        try:\n",
    "            # fit dataframe and transfer to csv for every webpage \n",
    "            review = pd.DataFrame({\n",
    "                'Restaurant Name': res_names,\n",
    "                'Restaurant Type': res_types,\n",
    "                'Reviewer\\'s Name': cust_names,\n",
    "                'Rating': cust_ratings,\n",
    "                'Comment': cust_comments, \n",
    "            })\n",
    "\n",
    "            print(review.info())\n",
    "            if start == 0:\n",
    "                review.to_csv('./data/trip-advisor-comments.csv', mode='a', index=False)\n",
    "            else:\n",
    "                review.to_csv('./data/trip-advisor-comments.csv', mode='a', index=False, header=False)\n",
    "            clear_output(wait = True)\n",
    "        \n",
    "        except:\n",
    "            print(f\"Unable to scrape LINK {count+start} due to unequal elements in the columns. Moving on...\")\n",
    "            # empty the list for the next webpage\n",
    "            cust_names = []\n",
    "            cust_ratings = []\n",
    "            cust_comments = []\n",
    "            res_names = []\n",
    "            res_types = []\n",
    "            continue\n",
    "            \n",
    "        # empty the list for the next webpage\n",
    "        cust_names = []\n",
    "        cust_ratings = []\n",
    "        cust_comments = []\n",
    "        res_names = []\n",
    "        res_types = []\n",
    "\n",
    "    print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine number of requests (each request is 10 entries)\n",
    "REQUESTS = 10\n",
    "start_list = [s for s in range(0,1014,50)]\n",
    "end_list = [e for e in range(49,1014,50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000]\n",
      "[49, 99, 149, 199, 249, 299, 349, 399, 449, 499, 549, 599, 649, 699, 749, 799, 849, 899, 949, 999]\n"
     ]
    }
   ],
   "source": [
    "# test values\n",
    "print(start_list)\n",
    "print(end_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALLING OF FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for scraping link 50: 48.78237295150757 seconds\n",
      "DONE\n",
      "Number of entries: 5000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Restaurant Name  5000 non-null   object\n",
      " 1   Restaurant Type  5000 non-null   object\n",
      " 2   Reviewer's Name  5000 non-null   object\n",
      " 3   Rating           5000 non-null   int64 \n",
      " 4   Comment          5000 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 195.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# link 0 - 49\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[0], end=end_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for scraping link 100: 73.11896085739136 seconds\n",
      "DONE\n",
      "Number of entries: 4971\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4971 entries, 0 to 4970\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Restaurant Name  4971 non-null   object\n",
      " 1   Restaurant Type  4971 non-null   object\n",
      " 2   Reviewer's Name  4971 non-null   object\n",
      " 3   Rating           4971 non-null   int64 \n",
      " 4   Comment          4971 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 194.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# link 50 - 99\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[1], end=end_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for scraping link 150: 74.75528454780579 seconds\n",
      "DONE\n",
      "Number of entries: 5000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Restaurant Name  5000 non-null   object\n",
      " 1   Restaurant Type  5000 non-null   object\n",
      " 2   Reviewer's Name  5000 non-null   object\n",
      " 3   Rating           5000 non-null   int64 \n",
      " 4   Comment          5000 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 195.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# link 100 - 149\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[2], end=end_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for scraping link 200: 63.61752152442932 seconds\n",
      "DONE\n",
      "Number of entries: 4985\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4985 entries, 0 to 4984\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Restaurant Name  4985 non-null   object\n",
      " 1   Restaurant Type  4985 non-null   object\n",
      " 2   Reviewer's Name  4985 non-null   object\n",
      " 3   Rating           4985 non-null   int64 \n",
      " 4   Comment          4985 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 194.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# link 150 - 199\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[3], end=end_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for scraping link 250: 76.94319868087769 seconds\n",
      "DONE\n",
      "Number of entries: 4880\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4880 entries, 0 to 4879\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Restaurant Name  4880 non-null   object\n",
      " 1   Restaurant Type  4880 non-null   object\n",
      " 2   Reviewer's Name  4880 non-null   object\n",
      " 3   Rating           4880 non-null   int64 \n",
      " 4   Comment          4880 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 190.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# link 200 - 249\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[4], end=end_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for scraping link 300: 68.3052167892456 seconds\n",
      "DONE\n",
      "Number of entries: 4965\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4965 entries, 0 to 4964\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Restaurant Name  4965 non-null   object\n",
      " 1   Restaurant Type  4965 non-null   object\n",
      " 2   Reviewer's Name  4965 non-null   object\n",
      " 3   Rating           4965 non-null   int64 \n",
      " 4   Comment          4965 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 194.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# link 250 - 299\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[5], end=end_list[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for scraping link 350: 64.7284643650055 seconds\n",
      "DONE\n",
      "Number of entries: 4984\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4984 entries, 0 to 4983\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Restaurant Name  4984 non-null   object\n",
      " 1   Restaurant Type  4984 non-null   object\n",
      " 2   Reviewer's Name  4984 non-null   object\n",
      " 3   Rating           4984 non-null   int64 \n",
      " 4   Comment          4984 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 194.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# link 300 - 349\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[6], end=end_list[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# got error\n",
    "# link 350 - 399\n",
    "#scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[7], end=end_list[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for scraping link 360: 60.504833698272705 seconds\n",
      "DONE\n",
      "Number of entries: 992\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 992 entries, 0 to 991\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Restaurant Name  992 non-null    object\n",
      " 1   Restaurant Type  992 non-null    object\n",
      " 2   Reviewer's Name  992 non-null    object\n",
      " 3   Rating           992 non-null    int64 \n",
      " 4   Comment          992 non-null    object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 38.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# link 350 - 359\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=350, end=359)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for scraping link 370: 59.58866786956787 seconds\n",
      "DONE\n",
      "Number of entries: 990\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 990 entries, 0 to 989\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Restaurant Name  990 non-null    object\n",
      " 1   Restaurant Type  990 non-null    object\n",
      " 2   Reviewer's Name  990 non-null    object\n",
      " 3   Rating           990 non-null    int64 \n",
      " 4   Comment          990 non-null    object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 38.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# link 360 - 369\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=360, end=369)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for scraping link 380: 73.09391021728516 seconds\n",
      "DONE\n",
      "Number of entries: 1000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Restaurant Name  1000 non-null   object\n",
      " 1   Restaurant Type  1000 non-null   object\n",
      " 2   Reviewer's Name  1000 non-null   object\n",
      " 3   Rating           1000 non-null   int64 \n",
      " 4   Comment          1000 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 39.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# link 370 - 379\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=370, end=379)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for scraping link 390: 72.13982772827148 seconds\n",
      "DONE\n",
      "Number of entries: 991\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 991 entries, 0 to 990\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Restaurant Name  991 non-null    object\n",
      " 1   Restaurant Type  991 non-null    object\n",
      " 2   Reviewer's Name  991 non-null    object\n",
      " 3   Rating           991 non-null    int64 \n",
      " 4   Comment          991 non-null    object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 38.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# link 380 - 389\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=380, end=389)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for scraping link 399: 68.3887779712677 seconds\n",
      "DONE\n",
      "Number of entries: 891\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Restaurant Name  891 non-null    object\n",
      " 1   Restaurant Type  891 non-null    object\n",
      " 2   Reviewer's Name  891 non-null    object\n",
      " 3   Rating           891 non-null    int64 \n",
      " 4   Comment          891 non-null    object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 34.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# link 390 - 398 -> got problem in 399\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=390, end=398)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for scraping link 450: 61.41247820854187 seconds\n",
      "DONE\n",
      "Number of entries: 4964\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4964 entries, 0 to 4963\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Restaurant Name  4964 non-null   object\n",
      " 1   Restaurant Type  4964 non-null   object\n",
      " 2   Reviewer's Name  4964 non-null   object\n",
      " 3   Rating           4964 non-null   int64 \n",
      " 4   Comment          4964 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 194.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# link 400 - 449\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[8], end=end_list[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for scraping link 500: 89.59984612464905 seconds\n",
      "DONE\n",
      "Number of entries: 4939\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4939 entries, 0 to 4938\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Restaurant Name  4939 non-null   object\n",
      " 1   Restaurant Type  4939 non-null   object\n",
      " 2   Reviewer's Name  4939 non-null   object\n",
      " 3   Rating           4939 non-null   int64 \n",
      " 4   Comment          4939 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 193.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# link 450 - 499\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[9], end=end_list[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## made some code modification from this point onwards to curb with 'arrays must all be same length' problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for scraping link 550: 76.73704671859741 seconds\n",
      "Number of entries: 100\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Restaurant Name  100 non-null    object\n",
      " 1   Restaurant Type  100 non-null    object\n",
      " 2   Reviewer's Name  100 non-null    object\n",
      " 3   Rating           100 non-null    int64 \n",
      " 4   Comment          100 non-null    object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 4.0+ KB\n",
      "None\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# link 500 - 549\n",
    "scraper_v2(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[10], end=end_list[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# link 550 - 599\n",
    "scraper_v2(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[11], end=579)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "scraper_v2(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=580, end=end_list[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# link 600 - 649\n",
    "scraper_v2(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[12], end=end_list[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# link 650 - 699\n",
    "scraper_v2(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[13], end=end_list[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# link 700 - 749\n",
    "scraper_v2(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[14], end=end_list[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# link 750 - 799\n",
    "scraper_v2(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[15], end=end_list[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# link 800 - 849\n",
    "scraper_v2(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[16], end=end_list[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# link 850 - 899\n",
    "scraper_v2(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[17], end=end_list[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# link 900 - 949\n",
    "scraper_v2(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[18], end=end_list[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# link 950 - 999\n",
    "scraper_v2(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[19], end=end_list[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# link 1000 - 1013\n",
    "scraper_v2(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[20], end=1012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
