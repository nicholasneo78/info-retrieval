{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second level scraper code to scrape the details of the restaurants and also the comments of the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from requests import get\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from time import time \n",
    "from IPython.core.display import clear_output\n",
    "from warnings import warn\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Restaurant Type</th>\n",
       "      <th>Webpage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Positano @ RP</td>\n",
       "      <td>Italian, European</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Grand Shanghai Restaurant</td>\n",
       "      <td>Chinese, Asian</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. Fu Lin Men (NSRCC)</td>\n",
       "      <td>Chinese, Seafood</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. Entre-Nous creperie</td>\n",
       "      <td>French, European</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. NOX - Dine in the Dark</td>\n",
       "      <td>European, Fusion</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6. The Mind Cafe</td>\n",
       "      <td>Cafe, Pub</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7. Song Garden</td>\n",
       "      <td>Chinese, Asian</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8. Fu Lin Men (CSC)</td>\n",
       "      <td>Chinese, Asian</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9. Melt Cafe</td>\n",
       "      <td>International</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10. Positano Risto</td>\n",
       "      <td>Italian, Pizza</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Restaurant Name    Restaurant Type  \\\n",
       "0              1. Positano @ RP  Italian, European   \n",
       "1  2. Grand Shanghai Restaurant     Chinese, Asian   \n",
       "2         3. Fu Lin Men (NSRCC)   Chinese, Seafood   \n",
       "3        4. Entre-Nous creperie   French, European   \n",
       "4     5. NOX - Dine in the Dark   European, Fusion   \n",
       "5              6. The Mind Cafe          Cafe, Pub   \n",
       "6                7. Song Garden     Chinese, Asian   \n",
       "7           8. Fu Lin Men (CSC)     Chinese, Asian   \n",
       "8                  9. Melt Cafe      International   \n",
       "9            10. Positano Risto     Italian, Pizza   \n",
       "\n",
       "                                             Webpage  \n",
       "0  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "1  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "2  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "3  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "4  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "5  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "6  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "7  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "8  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "9  https://www.tripadvisor.com.sg/Restaurant_Revi...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve dataframe of links scraped previously\n",
    "links_df = pd.read_csv('./data/trip-advisor-scraper-main.csv')\n",
    "links_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positano @ RP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grand Shanghai Restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fu Lin Men (NSRCC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Entre-Nous creperie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX - Dine in the Dark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Restaurant Name\n",
       "0              Positano @ RP\n",
       "1  Grand Shanghai Restaurant\n",
       "2         Fu Lin Men (NSRCC)\n",
       "3        Entre-Nous creperie\n",
       "4     NOX - Dine in the Dark"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning of name in the restaurant name column using regex\n",
    "regex = '^([0-9])+\\. '\n",
    "links_df['Restaurant Name'].replace(regex,'',regex=True, inplace = True)\n",
    "links_df[['Restaurant Name']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Restaurant Type</th>\n",
       "      <th>Webpage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positano @ RP</td>\n",
       "      <td>Italian, European</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grand Shanghai Restaurant</td>\n",
       "      <td>Chinese, Asian</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fu Lin Men (NSRCC)</td>\n",
       "      <td>Chinese, Seafood</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Entre-Nous creperie</td>\n",
       "      <td>French, European</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX - Dine in the Dark</td>\n",
       "      <td>European, Fusion</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Restaurant Name    Restaurant Type  \\\n",
       "0              Positano @ RP  Italian, European   \n",
       "1  Grand Shanghai Restaurant     Chinese, Asian   \n",
       "2         Fu Lin Men (NSRCC)   Chinese, Seafood   \n",
       "3        Entre-Nous creperie   French, European   \n",
       "4     NOX - Dine in the Dark   European, Fusion   \n",
       "\n",
       "                                             Webpage  \n",
       "0  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "1  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "2  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "3  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "4  https://www.tripadvisor.com.sg/Restaurant_Revi...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1013"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the links out\n",
    "#list(links_df[\"Webpage\"])\n",
    "# check if length is correct\n",
    "len(list(links_df[\"Webpage\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d21180746-Reviews-Positano_RP-Singapore.html',\n",
       " 'https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d1145149-Reviews-Grand_Shanghai_Restaurant-Singapore.html',\n",
       " 'https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d17171783-Reviews-Fu_Lin_Men_NSRCC-Singapore.html',\n",
       " 'https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d1193730-Reviews-Entre_Nous_creperie-Singapore.html',\n",
       " 'https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d4611806-Reviews-NOX_Dine_in_the_Dark-Singapore.html']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store links as a list\n",
    "LIST_OF_LINKS = list(links_df[\"Webpage\"])\n",
    "# show first 5 links\n",
    "LIST_OF_LINKS[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100', '110', '120', '130', '140', '150', '160', '170', '180', '190', '200', '210', '220', '230', '240', '250', '260', '270', '280', '290', '300', '310', '320', '330', '340', '350', '360', '370', '380', '390', '400', '410', '420', '430', '440', '450', '460', '470', '480', '490', '500'] \n",
      "Number of pages scraped: 51\n"
     ]
    }
   ],
   "source": [
    "# get the start value for every new page in yelp\n",
    "start_of_new_page = [str(i) for i in range(0,501,10)]\n",
    "# debug\n",
    "print(start_of_new_page, end=' ')\n",
    "print(f'\\nNumber of pages scraped: {len(start_of_new_page)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scraper(list_of_links, num_req, start, end):\n",
    "    # redeclaring lists to store data in multiple values\n",
    "    cust_names = []\n",
    "    cust_ratings = []\n",
    "    cust_comments = []\n",
    "    res_names = []\n",
    "    res_types = []\n",
    "\n",
    "    # counter\n",
    "    count = 0\n",
    "\n",
    "    # flag variable to check the scrape\n",
    "    # if unsuccessful scrape, try again\n",
    "    unsuccessful = True\n",
    "\n",
    "    # preparing the monitoring of the loop\n",
    "    start_time = time()\n",
    "\n",
    "    ### ----- \n",
    "\n",
    "    # for every comment in the interval of 10\n",
    "    for link_raw in list_of_links[start:end]:\n",
    "        loop_time = time()\n",
    "        count+=1 # increment count to determine which link it is being scraped\n",
    "        requests=1 # reset requests count for different webpage\n",
    "        # print(f'----- LINK {count} -----')\n",
    "        for pageStart in start_of_new_page:\n",
    "\n",
    "            # Break the loop if the number of requests is greater than expected\n",
    "            if requests > num_req:\n",
    "                #warn('Number of requests was greater than expected.')\n",
    "                break\n",
    "\n",
    "            unsuccessful = True\n",
    "            fail_count = 0\n",
    "\n",
    "            while unsuccessful:\n",
    "                # make a get request\n",
    "                #response = get(f'https://www.yelp.com/biz/jumbo-seafood-singapore-4?start={pageStart}')\n",
    "                #response = get(f'https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d7348336-Reviews-or{pageStart}-Sunday_Folks-Singapore.html')\n",
    "                link_array = link_raw.split('Reviews-')\n",
    "                link = link_array[0] + 'Reviews-' + 'or' + str(pageStart) + \"-\" +link_array[1]\n",
    "                # print(link)\n",
    "                response = get(link)\n",
    "\n",
    "                # pause the loop\n",
    "                sleep(randint(1,2))\n",
    "\n",
    "                # monitor the requests\n",
    "                elapsed_time = time() - start_time\n",
    "                print(f'LINK {count+start} REQUEST {requests}; Frequency: {requests/elapsed_time} requests/s')\n",
    "\n",
    "                # Parse the content of the request with BeautifulSoup\n",
    "                page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                # get the comment container for all 20 comments in a page\n",
    "                comment_containers = page_html.find_all('div', class_='review-container')\n",
    "\n",
    "                if len(comment_containers) != 0:\n",
    "                    print(f\"REQUEST {requests}: SUCCESS --> Failed Count: {fail_count}\")\n",
    "                    clear_output(wait = True)\n",
    "                    unsuccessful = False\n",
    "                else:\n",
    "                    fail_count+=1\n",
    "                    #print(f\"Request {requests}: unsuccessful scrape\") # debug\n",
    "                    pass\n",
    "            requests += 1\n",
    "\n",
    "            # for every comments in 10\n",
    "            for com in comment_containers:\n",
    "                # in case the scrape fail for that particular entry due to html tag issue\n",
    "                try:\n",
    "                    # append the restaurant name and type\n",
    "                    res_names.append(links_df[\"Restaurant Name\"][count+start-1])\n",
    "                    res_types.append(links_df[\"Restaurant Type\"][count+start-1])\n",
    "\n",
    "                    # scrape the customer name\n",
    "                    cust_name = com.find('div', class_='info_text pointer_cursor').text\n",
    "                    cust_names.append(cust_name)\n",
    "\n",
    "                    # scrape the customer ratings\n",
    "                    cust_rating_raw = com.find('div', class_ ='ui_column is-9').span['class']\n",
    "\n",
    "                    # convert the rating to an integer\n",
    "                    cust_rating = 0\n",
    "                    if cust_rating_raw[1] == 'bubble_50':\n",
    "                        cust_rating = 5\n",
    "                    elif cust_rating_raw[1] == 'bubble_40':\n",
    "                        cust_rating = 4\n",
    "                    elif cust_rating_raw[1] == 'bubble_30':\n",
    "                        cust_rating = 3\n",
    "                    elif cust_rating_raw[1] == 'bubble_20':\n",
    "                        cust_rating = 2\n",
    "                    elif cust_rating_raw[1] == 'bubble_10':\n",
    "                        cust_rating = 1\n",
    "                    else:\n",
    "                        cust_rating = 0\n",
    "                    cust_ratings.append(cust_rating)\n",
    "\n",
    "                    # scrape the customer comment\n",
    "                    cust_comment_raw = com.find('div', class_='entry').text\n",
    "\n",
    "                    # get rid of the unwanted characters like \"...\" and \"More\"\n",
    "                    comment_ = cust_comment_raw.replace(\"...\",\" \")\n",
    "\n",
    "                    # remove instances with \"More\" tab if there are more words\n",
    "                    cust_comment = \"\"\n",
    "                    if comment_[-5:] == \".More\":\n",
    "                        cust_comment = comment_[:-4]\n",
    "                    else:\n",
    "                        cust_comment = comment_\n",
    "\n",
    "                    cust_comments.append(cust_comment)\n",
    "                except:\n",
    "                    print(f'error in request {requests-1}')\n",
    "                    continue\n",
    "\n",
    "            # Throw a warning for non-200 status codes\n",
    "            if response.status_code != 200:\n",
    "                warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
    "        # check time needed to exceute one link\n",
    "        print(f'Time taken for scraping link {count+start}: {time() - loop_time} seconds')\n",
    "\n",
    "    print('DONE')\n",
    "    return cust_names, cust_ratings, cust_comments, res_names, res_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraper call function\n",
    "def scraper_call(list_of_links, num_req, start, end):\n",
    "    cust_names, cust_ratings, cust_comments, res_names, res_types = scraper(list_of_links = list_of_links, \n",
    "                                                                            num_req=num_req, \n",
    "                                                                            start=start, \n",
    "                                                                            end=end)\n",
    "    print(f'Number of entries: {len(cust_names)}')\n",
    "    review = pd.DataFrame({\n",
    "        'Restaurant Name': res_names,\n",
    "        'Restaurant Type': res_types,\n",
    "        'Reviewer\\'s Name': cust_names,\n",
    "        'Rating': cust_ratings,\n",
    "        'Comment': cust_comments, \n",
    "    })\n",
    "\n",
    "    print(review.info())\n",
    "    review.to_csv('./data/trip-advisor-comments.csv', mode='a', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine number of requests (each request is 10 entries)\n",
    "REQUESTS = 10\n",
    "start_list = [s for s in range(1,1014,50)]\n",
    "end_list = [e for e in range(50,1014,50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test values\n",
    "start_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINK 35 REQUEST 6; Frequency: 0.00360269083083521 requests/s\n",
      "REQUEST 6: SUCCESS --> Failed Count: 0\n"
     ]
    }
   ],
   "source": [
    "# link 0 - 50\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=0, end=end_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link 51 - 100\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[1], end=end_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link 101 - 150\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[2], end=end_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link 151 - 200\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[3], end=end_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link 201 - 250\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[4], end=end_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link 251 - 300\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[5], end=end_list[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link 301 - 350\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[6], end=end_list[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link 351 - 400\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[7], end=end_list[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link 401 - 450\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[8], end=end_list[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link 451 - 500\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[9], end=end_list[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link 501 - 550\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[10], end=end_list[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link 551 - 600\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[11], end=end_list[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link 601 - 650\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[12], end=end_list[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link 651 - 700\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[13], end=end_list[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link 701 - 750\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[14], end=end_list[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link 751 - 800\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[15], end=end_list[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link 801 - 850\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[16], end=end_list[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link 851 - 900\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[17], end=end_list[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link 901 - 950\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[17], end=end_list[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link 951 - 1000\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[18], end=end_list[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link 1001 - 1013\n",
    "scraper_call(list_of_links=LIST_OF_LINKS, num_req=REQUESTS, start=start_list[19], end=1013)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
