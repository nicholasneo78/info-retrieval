{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main scraper code to scrape the restaurant names and their corresponding webpage for the next level scrape (comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from requests import get\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from time import time \n",
    "from IPython.core.display import clear_output\n",
    "from warnings import warn\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small Test: Scraper code for one page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "# flag variable to check the scrape\n",
    "# if unsuccessful scrape, try again\n",
    "unsuccessful = True\n",
    "#count = 0\n",
    "while unsuccessful:\n",
    "    url = 'https://www.tripadvisor.com.sg/Restaurants-g294265-Singapore.html'\n",
    "    # make request to the site\n",
    "    response = get(url)\n",
    "    html_soup = BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "    # find all with the same class tag\n",
    "    res_containers = html_soup.find_all('div', class_='_1llCuDZj')\n",
    "    print(type(res_containers))\n",
    "    # check the number entries in a page and to determine the next page value for skipping\n",
    "    print(len(res_containers))\n",
    "    \n",
    "    # pause the loop\n",
    "    sleep(randint(2,5))\n",
    "    \n",
    "    if len(res_containers) != 0:\n",
    "        unsuccessful = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "# values in the tags of the second entry\n",
    "first_comment = res_containers[1]\n",
    "#first_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Positano @ RP'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get name of first stall\n",
    "cust_name = first_comment.find('a', class_='_15_ydu6b').text\n",
    "cust_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'https://www.tripadvisor.com.sg'\n",
    "cust_name = []\n",
    "webpage_list = []\n",
    "temp_str = ''\n",
    "for i,j in enumerate(res_containers):\n",
    "    # to remove ads that may be repetitive\n",
    "    if i%6 == 0:\n",
    "        continue\n",
    "    else:\n",
    "        cust_name.append(j.find('a', class_='_15_ydu6b').text)\n",
    "        temp_str = base + j.find('a', class_='_15_ydu6b').get('href')\n",
    "        webpage_list.append(temp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scrape restaurant name\n",
    "#cust_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#webpage_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scrape website\n",
    "first_comment = res_containers[6]\n",
    "#first_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'https://www.tripadvisor.com.sg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d12594724-Reviews-The_Lobby_Lounge-Singapore.html'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webpage = first_comment.find('a', class_='_15_ydu6b').get('href')\n",
    "base+webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Scraping of multiple pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '30', '60', '90', '120', '150', '180', '210', '240', '270', '300', '330', '360', '390', '420', '450', '480', '510', '540', '570', '600', '630', '660', '690', '720', '750', '780', '810', '840', '870', '900', '930', '960', '990', '1020'] \n",
      "Number of pages scraped: 35\n"
     ]
    }
   ],
   "source": [
    "# get the start value for every new page in tripadvisor\n",
    "start = [str(i) for i in range(0,1021,30)]\n",
    "# debug\n",
    "print(start, end=' ')\n",
    "# check number of pages scraped\n",
    "print(f'\\nNumber of pages scraped: {len(start)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request 1; Frequency: 0.10368395978560285 requests/s\n",
      "Request 1: SUCCESS --> Failed Count: 0\n",
      "Request 2; Frequency: 0.11001053037113812 requests/s\n",
      "Request 2: SUCCESS --> Failed Count: 0\n",
      "Request 3; Frequency: 0.11685186992623413 requests/s\n",
      "Request 3: SUCCESS --> Failed Count: 0\n",
      "Request 4; Frequency: 0.11577443293167936 requests/s\n",
      "Request 4: SUCCESS --> Failed Count: 0\n",
      "Request 5; Frequency: 0.1193772733154738 requests/s\n",
      "Request 5: SUCCESS --> Failed Count: 0\n",
      "Request 6; Frequency: 0.11613744230963961 requests/s\n",
      "Request 6: SUCCESS --> Failed Count: 0\n",
      "Request 7; Frequency: 0.11484452186802077 requests/s\n",
      "Request 7: SUCCESS --> Failed Count: 0\n",
      "Request 8; Frequency: 0.11316944137673787 requests/s\n",
      "Request 8: SUCCESS --> Failed Count: 0\n",
      "Request 9; Frequency: 0.1152557608834362 requests/s\n",
      "Request 9: SUCCESS --> Failed Count: 0\n",
      "Request 10; Frequency: 0.11715618013665464 requests/s\n",
      "Request 10: SUCCESS --> Failed Count: 0\n",
      "Request 11; Frequency: 0.1158080490615032 requests/s\n",
      "Request 11: SUCCESS --> Failed Count: 0\n",
      "Request 12; Frequency: 0.11556008190725925 requests/s\n",
      "Request 12: SUCCESS --> Failed Count: 0\n",
      "Request 13; Frequency: 0.11438354331554579 requests/s\n",
      "Request 13: SUCCESS --> Failed Count: 0\n",
      "Request 14; Frequency: 0.1134383259577396 requests/s\n",
      "Request 14: SUCCESS --> Failed Count: 0\n",
      "Request 15; Frequency: 0.11607502631488971 requests/s\n",
      "Request 15: SUCCESS --> Failed Count: 0\n",
      "Request 16; Frequency: 0.11693346327484556 requests/s\n",
      "Request 16: SUCCESS --> Failed Count: 0\n",
      "Request 17; Frequency: 0.1194537475736889 requests/s\n",
      "Request 17: SUCCESS --> Failed Count: 0\n",
      "Request 18; Frequency: 0.12176604305489207 requests/s\n",
      "Request 18: SUCCESS --> Failed Count: 0\n",
      "Request 19; Frequency: 0.12303518546323372 requests/s\n",
      "Request 19: SUCCESS --> Failed Count: 0\n",
      "Request 20; Frequency: 0.12360313276516535 requests/s\n",
      "Request 20: SUCCESS --> Failed Count: 0\n",
      "Request 21; Frequency: 0.12410192105371586 requests/s\n",
      "Request 21: SUCCESS --> Failed Count: 0\n",
      "Request 22; Frequency: 0.12530051908565154 requests/s\n",
      "Request 22: SUCCESS --> Failed Count: 0\n",
      "Request 23; Frequency: 0.12528314195024143 requests/s\n",
      "Request 23: SUCCESS --> Failed Count: 0\n",
      "Request 24; Frequency: 0.12555617969876184 requests/s\n",
      "Request 24: SUCCESS --> Failed Count: 0\n",
      "Request 25; Frequency: 0.12646608281610766 requests/s\n",
      "Request 25: SUCCESS --> Failed Count: 0\n",
      "Request 26; Frequency: 0.1272087895429813 requests/s\n",
      "Request 26: SUCCESS --> Failed Count: 0\n",
      "Request 27; Frequency: 0.12630058253284754 requests/s\n",
      "Request 27: SUCCESS --> Failed Count: 0\n",
      "Request 28; Frequency: 0.1266337093882712 requests/s\n",
      "Request 28: SUCCESS --> Failed Count: 0\n",
      "Request 29; Frequency: 0.12630123737883772 requests/s\n",
      "Request 29: SUCCESS --> Failed Count: 0\n",
      "Request 30; Frequency: 0.12646458506440253 requests/s\n",
      "Request 30: SUCCESS --> Failed Count: 0\n",
      "Request 31; Frequency: 0.12754075019275046 requests/s\n",
      "Request 31: SUCCESS --> Failed Count: 0\n",
      "Request 32; Frequency: 0.1287535702944419 requests/s\n",
      "Request 32: SUCCESS --> Failed Count: 0\n",
      "Request 33; Frequency: 0.12868143705388338 requests/s\n",
      "Request 33: SUCCESS --> Failed Count: 0\n",
      "Request 34; Frequency: 0.12916706759363583 requests/s\n",
      "Request 34: SUCCESS --> Failed Count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicholasneo78\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:28: UserWarning: Number of requests was greater than expected.\n"
     ]
    }
   ],
   "source": [
    "# redeclaring lists to store data in\n",
    "\n",
    "# multiple values\n",
    "res_list = []\n",
    "web_list = []\n",
    "base = 'https://www.tripadvisor.com.sg'\n",
    "\n",
    "# number of requests\n",
    "REQUESTS = len(start)-1\n",
    "\n",
    "# flag variable to check the scrape\n",
    "# if unsuccessful scrape, try again\n",
    "unsuccessful = True\n",
    "\n",
    "# preparing the monitoring of the loop\n",
    "start_time = time()\n",
    "requests = 1 # start request with request 1\n",
    "\n",
    "# for every pages of stores in an interval of 30\n",
    "for pageStart in start:\n",
    "    \n",
    "    # Throw a warning for non-200 status codes\n",
    "    if response.status_code != 200:\n",
    "        warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
    "\n",
    "    # Break the loop if the number of requests is greater than expected\n",
    "    if requests > REQUESTS:\n",
    "        warn('Number of requests was greater than expected.')\n",
    "        break\n",
    "        \n",
    "    unsuccessful = True\n",
    "    fail_count = 0\n",
    "    \n",
    "    while unsuccessful:\n",
    "        # make a get request\n",
    "        #response = get(f'https://www.yelp.com/biz/jumbo-seafood-singapore-4?start={pageStart}')\n",
    "        #response = get(f'https://www.tripadvisor.com.sg/Restaurant_Review-g294265-d7348336-Reviews-or{pageStart}-Sunday_Folks-Singapore.html')\n",
    "        response = get(f'https://www.tripadvisor.com.sg/Restaurants-g294265-oa{pageStart}-Singapore.html')\n",
    "        \n",
    "        # pause the loop\n",
    "        sleep(randint(3,5))\n",
    "\n",
    "        # monitor the requests\n",
    "        elapsed_time = time() - start_time\n",
    "        print(f'Request {requests}; Frequency: {requests/elapsed_time} requests/s')\n",
    "        #clear_output(wait = True)\n",
    "\n",
    "        # Parse the content of the request with BeautifulSoup\n",
    "        page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # get the comment container for all 20 comments in a page\n",
    "        res_containers = page_html.find_all('div', class_='_1llCuDZj')\n",
    "        \n",
    "        if len(res_containers) != 0:\n",
    "            print(f\"Request {requests}: SUCCESS --> Failed Count: {fail_count}\")\n",
    "            unsuccessful = False\n",
    "        else:\n",
    "            fail_count+=1\n",
    "            #print(f\"Request {requests}: unsuccessful scrape\") # debug\n",
    "            pass\n",
    "    requests += 1\n",
    "    \n",
    "    for idx, res in enumerate(res_containers):\n",
    "        # to remove ads that may be repetitive\n",
    "        if idx%6 == 0:\n",
    "            continue\n",
    "        else:\n",
    "            # scrape the restaurant names\n",
    "            res_name = res.find('a', class_='_15_ydu6b').text\n",
    "            res_list.append(res_name)\n",
    "\n",
    "            # scrape the webpage of the restaurant\n",
    "            web_name = base + res.find('a', class_='_15_ydu6b').get('href')\n",
    "            web_list.append(web_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1020"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of entries\n",
    "len(res_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit values scraped into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1020 entries, 0 to 1019\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Restaurant's Name  1020 non-null   object\n",
      " 1   Webpage            1020 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 16.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "res_review = pd.DataFrame({\n",
    "    'Restaurant\\'s Name': res_list,\n",
    "    'Webpage': web_list,\n",
    "})\n",
    "\n",
    "print(res_review.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant's Name</th>\n",
       "      <th>Webpage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Positano @ RP</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Grand Shanghai Restaurant</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. Fu Lin Men (NSRCC)</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. Entre-Nous creperie</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. NOX - Dine in the Dark</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6. The Mind Cafe</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7. Song Garden</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8. Fu Lin Men (CSC)</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9. Melt Cafe</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10. Positano Risto</td>\n",
       "      <td>https://www.tripadvisor.com.sg/Restaurant_Revi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Restaurant's Name  \\\n",
       "0              1. Positano @ RP   \n",
       "1  2. Grand Shanghai Restaurant   \n",
       "2         3. Fu Lin Men (NSRCC)   \n",
       "3        4. Entre-Nous creperie   \n",
       "4     5. NOX - Dine in the Dark   \n",
       "5              6. The Mind Cafe   \n",
       "6                7. Song Garden   \n",
       "7           8. Fu Lin Men (CSC)   \n",
       "8                  9. Melt Cafe   \n",
       "9            10. Positano Risto   \n",
       "\n",
       "                                             Webpage  \n",
       "0  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "1  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "2  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "3  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "4  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "5  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "6  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "7  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "8  https://www.tripadvisor.com.sg/Restaurant_Revi...  \n",
       "9  https://www.tripadvisor.com.sg/Restaurant_Revi...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_review.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_review.to_csv('./data/trip-advisor-scraper-main.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
